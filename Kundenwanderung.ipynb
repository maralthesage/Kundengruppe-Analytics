{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kundengruppe Analytiks\n",
    "\n",
    "In this notebook, we define customer categories based on the data we have in VS4, connect them with some other tables, like the rechnungen, the statistiks and teh newsletter customers, so we have a better view of each customer group. and we then compute their last half-year analytics to see how much revenue each group has brought us.\n",
    "\n",
    "There are some data quality issues that demanded changes in the regular implementation, namely:\n",
    "\n",
    "- the Neukunden-1 are customers who are added to our system in the current half-year, and even though, we are analyzing the last half-year, we had these Neukunden to our analytiks too.\n",
    "- there are some Neukunden-1 customers, whose order date (AUF_ANLAGE) is in 2024, but they are oddly considered Neukunden-1. That is because, the decision to categorize the neukunden-1 group comes down to SYS_ANLAGE (Date of registry in the system) and ERSTKAUF (the first order-date). now this ERSTKAUF column actually has the date that the invoice was created, that can be different, and something way apart from the date that the customer had made their order. that explains this inconsistency.\n",
    "- this is why, I have tried a few times to define this NK-1 group so that we have a complete list of all those who are Neukunden-1, along with their complete order details.\n",
    "- the dates are automated. that mean, whenever this code is run, the code looks at the today's date and decide, which Halfyear is the current one, which is the last one, and then makes the analytics, so the pipeline is complete, and it only requires updated data to create an updated analytics.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime as dt\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from helper import *\n",
    "from paths import *\n",
    "\n",
    "## Repetitive setting \n",
    "enc = 'cp850'\n",
    "sep = ';'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining the dates for the beginning and end of previous and Current HJ, as well as the Number of the Column in KW data\n",
    "result = get_half_year_info()\n",
    "last_hj = f'Z{result['number']}'\n",
    "current_hj = f'Z{result['number']+1}'\n",
    "prev_start = pd.to_datetime(result['prev_start'])\n",
    "prev_end = pd.to_datetime(result['prev_end'])\n",
    "current_start = pd.to_datetime(result['prev_start'] + relativedelta(months=6))\n",
    "current_end = pd.to_datetime(result['prev_end'] + relativedelta(months=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all required data\n",
    "kunden_segments = pd.read_excel(ks_path)\n",
    "kunden_segment_dict = dict(zip(kunden_segments['Alt'],kunden_segments['Neu']))\n",
    "kw = pd.read_csv(kw_path, sep=sep,encoding=enc,on_bad_lines='skip')\n",
    "adresse = pd.read_csv(adresse_path, sep=sep,encoding=enc)\n",
    "stat = pd.read_csv(stat_path, sep=sep,encoding=enc,usecols=['NUMMER','ERSTKAUF'])\n",
    "inx = pd.read_excel(inx_path,usecols=['NUMMER','NL_TYPE'])\n",
    "rechnung = pd.read_csv(rech_f01,sep=sep,encoding=enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## mapping the names to the codes in the columns related to last HJ and current HJ in the KW data\n",
    "kw[last_hj] = kw[last_hj].map(kunden_segment_dict)\n",
    "kw[current_hj] = kw[current_hj].map(kunden_segment_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data preprocessing to connect the clean tables together\n",
    "kw['NUMMER'] = process_id(kw['NUMMER'])\n",
    "\n",
    "adresse['NUMMER'] = process_id(adresse['NUMMER'])\n",
    "adresse['GEBURT'] = process_date(adresse['GEBURT'])\n",
    "adresse['SYS_ANLAGE'] = process_date(adresse['SYS_ANLAGE'])\n",
    "adresse = assign_age(adresse)\n",
    "adresse = assign_sources(adresse,'QUELLE')\n",
    "adresse['QUELLE'] = adresse['SOURCE']\n",
    "adresse = adresse.drop(columns=['SOURCE'])\n",
    "\n",
    "stat['NUMMER'] = process_id(stat['NUMMER'])\n",
    "stat['ERSTKAUF'] = process_date(stat['ERSTKAUF'])\n",
    "\n",
    "inx['NUMMER'] = process_id(inx['NUMMER'])\n",
    "rechnung['NUMMER'] = process_id(rechnung['NUMMER'])\n",
    "rechnung['AUF_ANLAGE'] = process_date(rechnung['AUF_ANLAGE'])\n",
    "rechnung = assign_sources(rechnung,'MEDIACODE')\n",
    "rechnung['MEDIACODE'] = rechnung['SOURCE']\n",
    "rechnung = rechnung.drop(columns=['SOURCE'])\n",
    "rechnung['HERKUNFT'] = rechnung['HERKUNFT'].astype(str).str.replace('.0','')\n",
    "rechnung['HERKUNFT'] = rechnung['HERKUNFT'].map(herkunft)\n",
    "## Cleaning up the Versandkosten items from rechnungen, also dividing the JG and HG PREIS to separate columns for further processing\n",
    "rechnung = rechnung[rechnung['WG_NAME'].str.contains(r'Versand',case=False,regex=True,na=False)==False]\n",
    "rechnung.loc[rechnung['ART_NR'].str.contains(r'^\\d+H[A-Z]\\d+',case=False,na=False,regex=True),'PREIS_JG'] = rechnung.loc[rechnung['ART_NR'].str.contains(r'^\\d+H[A-Z]\\d+',case=False,na=False,regex=True),'PREIS']\n",
    "rechnung.loc[rechnung['ART_NR'].str.contains(r'^\\d+H[A-Z]\\d+',case=False,na=False,regex=True)==False,'PREIS_HG'] = rechnung.loc[rechnung['ART_NR'].str.contains(r'^\\d+H[A-Z]\\d+',case=False,na=False,regex=True)==False,'PREIS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Copying rechnung to filter it to the dates of the last HJ\n",
    "rechnung_general = rechnung.copy()\n",
    "rechnung_general = rechnung_general[(rechnung_general['AUF_ANLAGE']>= prev_start)&(rechnung_general['AUF_ANLAGE']<= prev_end)]\n",
    "## Grouping the last HJ Rechnungen so we have certain values in cleanly named columns\n",
    "rechnung_gr = rechnung_general.groupby(['NUMMER']).agg(             ANZ_AUF=('AUFTRAG_NR','nunique'),\n",
    "                                                            AUF_ANLAGE=('AUF_ANLAGE','first'),\n",
    "                                                            MEDIACODE=('MEDIACODE','first'),\n",
    "                                                            UMSATZ_HG=('PREIS_HG','sum'),\n",
    "                                                            UMSATZ_JG=('PREIS_JG','sum'),\n",
    "                                                            HERKUNFT=('HERKUNFT','first')\n",
    "                                                            ).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merging tables to each other using the customer ID (NUMMER) column\n",
    "df = pd.merge(adresse,kw[['NUMMER',last_hj]],on='NUMMER',how='left')\n",
    "df = pd.merge(df,stat,on='NUMMER',how='left')\n",
    "df = pd.merge(df,inx,on='NUMMER',how='left')\n",
    "df = pd.merge(df,rechnung_gr,on='NUMMER',how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning up the df table, renaming the KW HJ column to Kundengruppe and removing duplicates from the data\n",
    "df = df[['NUMMER', 'ANREDE', 'TITEL', 'VORNAME', 'NAME', 'QUELLE', 'LKZ', 'PLZ', 'ORT',\n",
    "       'SYS_ANLAGE', 'AGE_GROUP',  last_hj, 'ERSTKAUF', 'NL_TYPE',\n",
    "       'ANZ_AUF', 'HERKUNFT',  'MEDIACODE','AUF_ANLAGE', 'UMSATZ_HG','UMSATZ_JG']]\n",
    "df = df.rename(columns={last_hj:'Kundengruppe'})\n",
    "df = df.drop_duplicates(subset='NUMMER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Defining interessenten customers, those who are in the system but have no orders\n",
    "df.loc[(df['ERSTKAUF'].isna()),'Kundengruppe'] = \"Interessenten\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## filtering out the customers who have joined us in the current HJ\n",
    "df = df[df['SYS_ANLAGE']<=prev_end]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NK-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Making the same grouping of the rechnung only for the current half year, so that we can use it for the Neukunden-1 group\n",
    "rechnung_current = rechnung.copy()\n",
    "rechnung_current = rechnung_current[(rechnung_current['AUF_ANLAGE']>= current_start)&(rechnung_current['AUF_ANLAGE']<=current_end)]\n",
    "\n",
    "rechnung_nk_gr = rechnung_current.groupby(['NUMMER']).agg(  ANZ_AUF=('AUFTRAG_NR','nunique'),\n",
    "                                                            AUF_ANLAGE=('AUF_ANLAGE','first'),\n",
    "                                                            MEDIACODE=('MEDIACODE','first'),\n",
    "                                                            UMSATZ_HG=('PREIS_HG','sum'),\n",
    "                                                            UMSATZ_JG=('PREIS_JG','sum'),\n",
    "                                                            HERKUNFT=('HERKUNFT','first')\n",
    "                                                            ).reset_index()\n",
    "\n",
    "## Selecting customers from the Adresse that are registered by us in the current halfyear\n",
    "nk_adresse = adresse.copy()\n",
    "nk_adresse = nk_adresse[nk_adresse['SYS_ANLAGE']>=current_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connecting all data\n",
    "nk_df = pd.merge(nk_adresse,kw[['NUMMER',current_hj]],on='NUMMER',how='left')\n",
    "nk_df = pd.merge(nk_df,stat,on='NUMMER',how='left')\n",
    "nk_df = pd.merge(nk_df,inx,on='NUMMER',how='left')\n",
    "nk_df = pd.merge(nk_df,rechnung_nk_gr,on='NUMMER',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Cleaning up the df table, renaming the KW HJ column to Kundengruppe and removing duplicates from the data\n",
    "\n",
    "nk_df = nk_df[['NUMMER', 'ANREDE', 'TITEL', 'VORNAME', 'NAME', 'QUELLE', 'LKZ', 'PLZ', 'ORT',\n",
    "       'SYS_ANLAGE', 'AGE_GROUP',  current_hj, 'ERSTKAUF', 'NL_TYPE',\n",
    "       'ANZ_AUF', 'HERKUNFT',  'MEDIACODE','AUF_ANLAGE', 'UMSATZ_HG','UMSATZ_JG']]\n",
    "nk_df = nk_df.rename(columns={current_hj:'Kundengruppe'})\n",
    "nk_df = nk_df.drop_duplicates(subset='NUMMER')\n",
    "## Those with ERSTKAUF datum are neukunden-1 those without it are Interessenten\n",
    "nk_df.loc[(nk_df['ERSTKAUF'].isna()),'Kundengruppe'] = \"Interessenten\"\n",
    "nk_df.loc[(nk_df['ERSTKAUF'].notna()),'Kundengruppe'] = \"Neukunden-1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Concatenating the last hj customers with current hj customers\n",
    "final_df = pd.concat([df,nk_df])\n",
    "final_df = final_df.drop_duplicates(subset='NUMMER')\n",
    "## Expanding the Neukunden-1 to those who are Interessenten but have an ERSTKAUF in the current hj\n",
    "final_df.loc[(final_df['SYS_ANLAGE']<=prev_end)&(final_df['Kundengruppe']=='Interessenten')&(final_df['ERSTKAUF']>=current_start),'Kundengruppe'] = 'Neukunden-1'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Remove their Rechnungs data, and once again merge them with the rechnungs data so they don't have missing values\n",
    "nk_final = final_df[final_df['Kundengruppe']=='Neukunden-1'][['NUMMER', 'ANREDE', 'TITEL', 'VORNAME', 'NAME', 'QUELLE', 'LKZ', 'PLZ',\n",
    "       'ORT', 'SYS_ANLAGE', 'AGE_GROUP', 'Kundengruppe', 'ERSTKAUF', 'NL_TYPE']]\n",
    "rechnung_nk_final_gr = rechnung.groupby(['NUMMER']).agg(  ANZ_AUF=('AUFTRAG_NR','nunique'),\n",
    "                                                            AUF_ANLAGE=('AUF_ANLAGE','first'),\n",
    "                                                            MEDIACODE=('MEDIACODE','first'),\n",
    "                                                            UMSATZ_HG=('PREIS_HG','sum'),\n",
    "                                                            UMSATZ_JG=('PREIS_JG','sum'),\n",
    "                                                            HERKUNFT=('HERKUNFT','first')\n",
    "                                                            ).reset_index()\n",
    "\n",
    "## Merging the customers with the rechnungen\n",
    "nk_final = nk_final.merge(rechnung_nk_final_gr,on='NUMMER',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## removing this group from the final_Df and then adding the freshly created neukunden to the final_df_list\n",
    "final_df = final_df[final_df['Kundengruppe'] != 'Neukunden-1']\n",
    "final_df = pd.concat([final_df,nk_final])\n",
    "## Removing duplicated Nummers\n",
    "final_df = final_df.drop_duplicates(subset=['NUMMER'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Removing Columns Anrede and Titel\n",
    "final_df = final_df.drop(columns=['ANREDE','TITEL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the Sum values for each kunden gruppe\n",
    "gesamts = final_df.groupby('Kundengruppe').agg(GESAMT_ANZ_AUF=('ANZ_AUF','sum'),\n",
    "                                     DURCHSCHNITT_ANZ_AUF=('ANZ_AUF','mean'),\n",
    "                                     GESAMT_UMSATZ_HG=('UMSATZ_HG','sum'),\n",
    "                                     GESAMT_UMSATZ_JG=('UMSATZ_JG','sum'),\n",
    "                                     ).reset_index()\n",
    "\n",
    "gesamts['GESAMT_UMSATZ'] = gesamts['GESAMT_UMSATZ_HG'] + gesamts['GESAMT_UMSATZ_JG']\n",
    "gesamts['DURCHSCHNITT_UMSATZ'] = gesamts['GESAMT_UMSATZ'] / gesamts['GESAMT_ANZ_AUF']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg = list(final_df[final_df['Kundengruppe'].notna()]['Kundengruppe'].unique())\n",
    "with pd.ExcelWriter('KundenInfo-2024-2HJ.xlsx',engine='xlsxwriter') as writer:\n",
    "    gesamts.to_excel(writer,index=False,sheet_name='Gesamt Analytik')\n",
    "    for item in kg:\n",
    "        print(item)\n",
    "        final_df[final_df['Kundengruppe'] == item].to_excel(writer,index=False,sheet_name=item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
